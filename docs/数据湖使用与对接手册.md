# 数据湖使用与对接手册

本文档说明 PaaS 数据湖的企业级能力：多 Cell 数据汇聚、数据资产管理、数据权限、统一报表与导出，以及**新 Cell 数据接入**、**报表配置**的完整步骤。所有对接均通过**标准化接口**完成，**不侵入业务 Cell 代码**，严格遵循解耦原则。

---

## 一、能力总览

| 能力 | 说明 | 接口 |
|------|------|------|
| 多 Cell 数据汇聚 | 全量/增量同步、数据清洗、格式标准化 | POST /api/datalake/ingest |
| 元数据管理 | 表/列注册与查询 | GET/PUT /api/datalake/metadata |
| 数据血缘 | 来源 Cell、同步类型、时间 | GET /api/datalake/lineage |
| 数据质量 | 规则配置与校验结果 | GET/POST /api/datalake/quality/rules |
| 敏感数据识别 | 列级标签（pii/phone/idno/email），导出脱敏 | GET/PUT /api/datalake/sensitive |
| 数据权限 | 表/行/字段级，按租户与角色 | GET/POST /api/datalake/permission |
| 统一报表 | 报表定义、执行、可视化大屏数据 | GET/POST /api/datalake/reports，GET .../reports/<id>/data |
| 数据导出 | CSV 导出 | POST /api/datalake/export，或 reports/.../data?format=csv |

所有接口需请求头：`Authorization`、`X-Tenant-Id`（租户隔离）；可选 `X-Role` / `X-Data-Role`（数据权限角色）。

---

## 二、部署与网关代理

- **数据湖服务**：独立进程，默认端口 8006。  
  - 启动：`python deploy/run_datalake.py` 或设置 `DATALAKE_PORT=8006`。  
- **网关代理**：在网关注入 `DATALAKE_URL=http://datalake:8006`（或本机 `http://localhost:8006`）后，网关将 `GET/POST /api/datalake` 及子路径转发至数据湖，前端与 Cell 统一访问网关即可，无需直连数据湖。

---

## 三、新 Cell 数据接入（不侵入 Cell 代码）

### 3.1 方式一：Cell 主动推送（推荐）

Cell 侧**仅需调用标准 HTTP 接口**，无需修改业务逻辑以外的代码（如定时任务或事件后挂载一条 HTTP 调用）。

**接口**：`POST /api/datalake/ingest`（经网关时为 `POST <GATEWAY_URL>/api/datalake/ingest`）

**请求体**：

```json
{
  "tenantId": "tenant-001",
  "cellId": "crm",
  "table": "opportunities",
  "syncType": "incremental",
  "records": [
    { "id": "opp-1", "name": "商机A", "stage": "proposal", "amount": 10000 },
    { "id": "opp-2", "name": "商机B", "stage": "qualification", "amount": 5000 }
  ]
}
```

- `tenantId`：租户 ID，与请求头 `X-Tenant-Id` 一致或在此指定；不传则用请求头。  
- `cellId`：细胞标识（如 crm、erp、wms），必填。  
- `table`：逻辑表名，必填。  
- `syncType`：`full` 全量（先清空该 tenant+cell+table 再写入），`incremental` 增量（追加）。  
- `records`：记录数组，每条为键值对；数据湖侧会做清洗与格式标准化（如空串转 null、日期格式统一）。

**响应**：201，`{ "ok": true, "count": N, "syncType": "incremental" }`。

**接入步骤**：

1. 在 Cell 内增加**独立**的同步逻辑（定时任务或事件发布后调用），仅发起 HTTP POST 到网关 `/api/datalake/ingest`，带上 `Authorization`、`X-Tenant-Id`。  
2. 不修改现有业务接口与表结构；仅“多写”一份到数据湖。  
3. （可选）在数据湖侧注册该表元数据：PUT /api/datalake/metadata，body 含 `cellId`、`table`、`columns`，便于血缘与质量配置。

### 3.2 方式二：平台侧拉取（配置化）

由平台侧定时任务或调度器，通过**网关**调用各 Cell 已暴露的标准查询接口（如 GET /api/v1/crm/opportunities），将返回结果再 POST 到数据湖 `/api/datalake/ingest`。  
- Cell 无需新增推送代码，只需已有只读 API；数据湖侧需配置拉取目标 URL、租户、cellId、table 与全量/增量策略。  
- 具体调度脚本与配置由部署侧在数据湖/运维侧实现，本文不展开脚本细节。

### 3.3 数据清洗与格式标准化

- 在数据湖侧对 `records` 做统一处理：空字符串转 null、日期字段统一为 YYYY-MM-DD 等。  
- Cell 无需改业务表结构，只需保证推送的 JSON 结构稳定；若有特殊字段要求，可在元数据中说明，由数据湖扩展清洗规则。

---

## 四、元数据、血缘、质量、敏感标签

### 4.1 元数据

- **注册**：`PUT /api/datalake/metadata`，body：`{ "cellId", "table", "columns": [ { "name", "type", "sensitive": true/false } ] }`。  
- **查询**：`GET /api/datalake/metadata?cellId=crm&table=opportunities` 或 GET 不传参数列出当前租户下所有已注册表。

### 4.2 血缘

- **查询**：`GET /api/datalake/lineage?cellId=crm&table=opportunities`，返回该表数据来源（如 push）、同步类型、时间等。

### 4.3 数据质量

- **添加规则**：`POST /api/datalake/quality/rules`，body：`{ "cellId", "table", "column", "rule": "not_null|range|enum", "params": {} }`。  
- **查询规则**：`GET /api/datalake/quality/rules?cellId=crm&table=opportunities`。

### 4.4 敏感数据

- **打标签**：`PUT /api/datalake/sensitive`，body：`{ "cellId", "table", "column", "tag": "pii|phone|idno|email" }`。  
- **查询标签**：`GET /api/datalake/sensitive?cellId=crm&table=opportunities`。  
- 导出或报表输出时，可按标签对列脱敏（由数据湖或报表引擎根据标签应用脱敏规则）。

---

## 五、数据权限（表/行/字段级）

- **添加规则**：`POST /api/datalake/permission`，body：  
  `{ "role", "cellId", "table", "scope": "table|row|field", "rowFilter": "dept_id=001", "allowedColumns": ["col1","col2"] }`。  
- **查询规则**：`GET /api/datalake/permission?role=user`。  
- 查询与报表执行时，数据湖按当前请求的租户 + 角色（请求头 `X-Tenant-Id`、`X-Role`/`X-Data-Role`）应用表/行/列权限，仅返回有权限的数据。

---

## 六、报表配置与导出

### 6.1 创建报表

**接口**：`POST /api/datalake/reports`  
**请求体**：

```json
{
  "id": "rpt-sales-by-stage",
  "name": "商机阶段分布",
  "datasource": { "cellId": "crm", "table": "opportunities" },
  "dimensions": ["stage", "owner_id"],
  "metrics": ["amount", "id"],
  "filters": {}
}
```

- `datasource`：数据来源，当前支持 `cellId` + `table`（来自数据湖已汇聚数据）。  
- `dimensions`：维度列；`metrics`：指标列；查询时按权限过滤后投影这些列。

### 6.2 执行报表与导出

- **取数**：`GET /api/datalake/reports/<report_id>/data?limit=1000`，返回 JSON 数组。  
- **导出 CSV**：`GET /api/datalake/reports/<report_id>/data?format=csv`，返回 CSV 文件下载。  
- **通用导出**：`POST /api/datalake/export`，body：`{ "cellId", "table" }` 或 `{ "reportId" }`，返回 CSV；同样受数据权限约束。

### 6.3 可视化大屏

- **创建大屏**：`POST /api/datalake/dashboards`，body：`{ "id", "name", "widgets": [ { "type", "reportId", "title" } ], "layout": {} }`。  
- **列表**：`GET /api/datalake/dashboards`。  
- 大屏数据由前端按需调用 `GET /api/datalake/reports/<report_id>/data` 等接口获取；数据湖仅提供数据 API，不包含前端渲染。

---

## 七、完整操作步骤速查

### 新 Cell 数据接入

1. 部署数据湖服务并配置网关 `DATALAKE_URL`。  
2. 在 Cell 内增加“推送”逻辑（定时或事件后）：POST 到网关 `/api/datalake/ingest`，body 含 `tenantId`、`cellId`、`table`、`syncType`、`records`，请求头带 `Authorization`、`X-Tenant-Id`。  
3. （可选）PUT /api/datalake/metadata 注册表结构；PUT /api/datalake/sensitive 标记敏感列；POST /api/datalake/quality/rules 配置质量规则。

### 报表配置

1. 确保目标数据已通过 ingest 入湖。  
2. POST /api/datalake/reports 创建报表（id、name、datasource、dimensions、metrics）。  
3. 配置数据权限：POST /api/datalake/permission，指定 role、cellId、table、scope、rowFilter 或 allowedColumns。  
4. 调用 GET /api/datalake/reports/<id>/data 或 ?format=csv 获取数据或导出。

---

## 八、解耦原则与数据隔离

- **不侵入 Cell**：业务 Cell 不依赖数据湖代码库；仅通过标准 HTTP 调用网关或数据湖的 ingest/query 等接口。  
- **数据隔离**：所有数据按 `tenant_id` 存储与查询；不同租户数据 100% 不互通。  
- **权限**：表/行/字段级权限在数据湖侧统一执行，Cell 无需实现权限逻辑。

---

**文档归属**：PaaS 数据湖 · 企业级能力  
**关联**：《接口设计说明书》、事件总线与跨细胞异步规范
