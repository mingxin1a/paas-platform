# 商用化性能优化建议

**版本**：1.0  
**目标**：满足商用验收「核心接口响应≤500ms、100 并发 5 分钟无报错、缓存使二次访问提升≥50%、批量操作无性能瓶颈」。

---

## 1. 性能瓶颈与现状

| 维度 | 现状 | 风险 |
|------|------|------|
| 核心接口响应 | 未做全量压测，部分 Cell 为内存 store，响应普遍较快 | 落库后若缺索引或 N+1 查询，P95 易超 500ms |
| 并发 | 未统一做 100 并发 5 分钟压测 | 线程/连接池、DB 连接数不足时易报错或超时 |
| 缓存 | 多数 Cell 未接入 Redis/本地缓存 | 核心查询二次访问无 50% 提升 |
| 批量 | 批量导入/导出接口存在，单次上限与超时未统一 | 1000 条/100 行可能超时或 OOM |

---

## 2. 具体优化方案

### 2.1 核心接口响应时间 ≤500ms（P95）

- **数据库**  
  - 所有按租户、时间、状态查询的列表接口：在 `tenant_id`、`created_at`、`status` 等字段上建组合索引（与各 cell 的 database_schema.sql 一致，生产落库时务必执行）。  
  - 避免 N+1：列表接口一次查询主表 + 必要关联（如订单带行项目数量），或使用批量 IN 查询后内存组装。
- **Cell 层**  
  - 分页强制：列表类接口强制 `pageSize` 上限（如 100），避免单次返回上万条。  
  - 大 JSON 响应：对「大对象」或「明细很多」的接口考虑分页或按需加载（如 360 视图只返回汇总，明细单独接口）。

**示例（索引）**：已在各 cell 的 `database_schema.sql` 中定义 `idx_tenant_*` 等，生产部署时需确认执行；若使用 ORM，确保生成的 SQL 使用到这些索引。

---

### 2.2 100 并发、持续 5 分钟无报错

- **网关**  
  - 网关到 Cell 的 HTTP 连接池：使用 `urllib.request` 时每次新建连接；若网关改用 `requests` 或 `httpx`，建议使用 Session 并配置连接池（如 pool_connections=50, pool_maxsize=100）。  
  - 超时：网关到 Cell 的超时建议 10–30s，避免长时间占用连接。
- **Cell**  
  - 若使用 Gunicorn/uWSGI：worker 数 ≥ CPU 核数 * 2；线程/协程模型下保证最大并发数 ≥100。  
  - 若 Cell 连 DB：配置连接池（如 SQLAlchemy `pool_size=20`, `max_overflow=10`），确保 100 并发下连接数在 DB 允许范围内。
- **压测**  
  - 使用 `deploy/core_business_flow_tests.py --load` 或独立压测脚本（如 locust）对 `GET /api/v1/crm/customers`、`GET /api/v1/erp/mm/materials` 等核心 GET 与关键 POST 做 100 并发、持续 5 分钟，统计 P95/P99 与错误率，目标：P95≤500ms、错误率 0%。

---

### 2.3 缓存使核心查询二次访问提升 ≥50%

- **适用接口**：各 Cell 的「列表首屏」与「热点查询」（如 CRM 客户列表、ERP 物料列表、WMS 库存汇总、MES 工单列表等）。
- **方案**  
  - 在 Cell 内或网关与 Cell 之间引入 Redis（或本地缓存如 cachetools）。  
  - 缓存 key 设计：`cell:tenant_id:接口标识:分页参数`（如 `crm:tenant1:customers:page1_pagesize20`）。  
  - TTL：列表类 60–300s；统计类 300–600s；明细单条可 60s 或按需失效。  
  - 写操作（创建/更新/删除）时删除或更新对应 key，避免脏读。
- **实现要点**  
  - 第一次请求未命中缓存，查 DB 并写入缓存；第二次请求命中缓存，直接返回。  
  - 若 DB 查询本身 80ms，缓存命中 5ms，则提升约 94%，满足「≥50%」；若 DB 查询 200ms，缓存 50ms，提升 75%。

**示例（Cell 内 Redis 缓存列表）**：

```python
# 伪代码：Flask/FastAPI 内
def get_customers_list(tenant_id, page, page_size):
    cache_key = f"crm:customers:{tenant_id}:{page}:{page_size}"
    cached = redis.get(cache_key)
    if cached:
        return json.loads(cached)
    data = db.customers_list(tenant_id, page, page_size)
    redis.setex(cache_key, 120, json.dumps(data))
    return data
```

---

### 2.4 批量操作（1000 条客户导入、100 行物料入库）

- **单次上限与超时**  
  - 在接口文档与《商用化问题整改清单》中明确：如「客户批量导入单次≤1000 条」「入库单行数≤500」「请求超时 30s」。  
  - 在接口内校验：超过上限直接返回 400，避免长时间占用与 OOM。
- **实现方式**  
  - 批量插入使用 DB 的 bulk insert（如 executemany 或 INSERT INTO ... VALUES (...),(...)...），避免循环单条 insert。  
  - 若单次 1000 条仍慢，可改为异步任务：接口立即返回 task_id，后台执行导入，前端轮询或 WebSocket 获取结果；此时需保证任务幂等与可重试。
- **导出**  
  - 大结果集导出使用流式响应或分页导出（如每页 1000 条，多次请求），避免单次返回百万行导致内存与超时问题。

---

## 3. 建议实施顺序

1. **P0**：生产落库后补齐索引、分页上限与连接池配置；执行 100 并发 5 分钟压测并达标。  
2. **P1**：为 3–5 个核心 Cell 的列表/统计接口增加 Redis 缓存，验证二次访问提升≥50%。  
3. **P2**：统一批量上限与超时、导出流式/分页；必要时引入异步任务与监控（如 Prometheus 请求延迟、错误率）。

---

## 4. 监控指标建议

- 网关：按 cell 与 path 统计 P50/P95/P99 延迟、QPS、5xx 率。  
- 各 Cell：/health、/metrics（若有）的可用性；若接入 Prometheus，暴露 `http_request_duration_seconds`、`http_requests_total`。  
- 缓存：命中率、key 数量、Redis 内存与连接数。  
- DB：连接池使用率、慢查询、锁等待。

上述指标可与《商用化问题整改清单》中「监控栈可部署」一并落地，便于持续验证性能与稳定性。
